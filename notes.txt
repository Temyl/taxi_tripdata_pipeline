Install s3fs pandas boto3 & pymongo globally (outside your virtual environment, through GitBash) to have some dataset preview
    pip install pymongo s3fs==0.4.2
Install airflow (venv)
    export AIRFLOW_HOME=~/airflow
    AIRFLOW_VERSION=2.7.1
    PYTHON_VERSION="$(python3 --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
    CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
    pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}" 
Install other packages (venv)
    pip install pandas s3fs==0.4.2 
    pip install pymongo 
    pip install configparser

Set up airflow (venv)
    airflow db migrate
    airflow users create --username ** --firstname ** --lastname ** --role Admin --email **
    airflow scheduler
    airflow webserver --port 8080

    airflow users create --username timi --firstname timi --lastname oye --role Admin --email dataengineering@10Alytics.org


Mongo DB connection options
link 1: 'mongodb+srv://student1:6u0N1fZ7cCd7j5uK@tenalytics.vecttgs.mongodb.net/?retryWrites=true&w=majority&appName=AtlasApp'
link 2: 'mongodb+srv://student2:OlGQuu9Dc75AKjZy@tenalytics.vecttgs.mongodb.net/?retryWrites=true&w=majority&appName=AtlasApp'